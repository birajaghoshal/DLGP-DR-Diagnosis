{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numpy version: 1.18.1\n",
      "Tensorflow version: 2.1.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import random\n",
    "import sys\n",
    "import argparse\n",
    "import csv\n",
    "from glob import glob\n",
    "import pickle\n",
    "import gzip\n",
    "import scipy\n",
    "import pandas as pd\n",
    "import keras\n",
    "import keras.layers as layers\n",
    "from keras import losses\n",
    "from keras import backend as K\n",
    "from keras.layers import Input, LSTM, Dense, Lambda, Conv1D, Conv2D, AveragePooling2D, AveragePooling1D, Flatten, MaxPooling2D, MaxPooling1D, Dropout, GlobalAveragePooling2D, GlobalAveragePooling1D\n",
    "from keras.models import Model, Sequential\n",
    "from keras.utils import Sequence\n",
    "from keras.preprocessing import image\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.callbacks import TensorBoard, EarlyStopping, ModelCheckpoint\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.optimizers import RMSprop, SGD\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from time import time\n",
    "from sklearn.metrics import  roc_curve, roc_auc_score, classification_report, confusion_matrix\n",
    "import glob\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "print(f\"Numpy version: {np.__version__}\")\n",
    "print(f\"Tensorflow version: {tf.__version__}\")\n",
    "\n",
    "random.seed(432)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  try:\n",
    "    tf.config.experimental.set_virtual_device_configuration(gpus[0], [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=6144)])\n",
    "  except RuntimeError as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Various constants.\n",
    "num_workers = 8\n",
    "#normalization_fn = rescale_min_1_to_1\n",
    "num_epochs = 200\n",
    "learning_rate = 1e-6\n",
    "decay = 4e-5\n",
    "min_delta_auc = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Buffer size for image shuffling.\n",
    "shuffle_buffer_size = 2048\n",
    "prefetch_buffer_size = 2 * 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize each data set.\n",
    "#train_dataset = lib.dataset.initialize_dataset(\n",
    "#    train_dir, train_batch_size,\n",
    "#    num_workers=num_workers, prefetch_buffer_size=prefetch_buffer_size,\n",
    "#    shuffle_buffer_size=shuffle_buffer_size, num_channels=num_channels,\n",
    "#    normalization_fn=normalization_fn)\n",
    "\n",
    "#val_dataset = lib.dataset.initialize_dataset(\n",
    "#    val_dir, val_batch_size,\n",
    "#    num_workers=num_workers, prefetch_buffer_size=prefetch_buffer_size,\n",
    "#    shuffle_buffer_size=shuffle_buffer_size, num_channels=num_channels,\n",
    "#    normalization_fn=normalization_fn, augmentation=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DIR = '/home/stoledoc/work/datanfs/stoledoc/jama16-retina-replication-master/data/eyepacs/train'\n",
    "TEST_DIR = '/home/stoledoc/work/datanfs/stoledoc/jama16-retina-replication-master/data/eyepacs/test'\n",
    "MESSIDOR2_DIR = '/home/stoledoc/work/datanfs/stoledoc/jama16-retina-replication-master/data/messidor2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "\n",
    "def preprocessing(image):\n",
    "    image = tf.image.random_brightness(image, 0.125)\n",
    "    image = tf.image.random_saturation(image, 0.5, 1.5)\n",
    "    image = tf.image.random_hue(image, 0.2)\n",
    "    image = tf.image.random_contrast(image, 0.5, 1.5)\n",
    "    return image\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "                                samplewise_center = True,\n",
    "                                horizontal_flip=True,\n",
    "                                rescale=1./255,\n",
    "                                preprocessing_function = preprocessing,\n",
    "                                validation_split=0.2\n",
    "                                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 45463 images belonging to 2 classes.\n",
      "Found 11364 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = datagen.flow_from_directory(\n",
    "    TRAIN_DIR, \n",
    "    target_size=(299, 299),  \n",
    "    color_mode='rgb',\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary',\n",
    "    subset='training'\n",
    ")\n",
    "\n",
    "val_generator = datagen.flow_from_directory(\n",
    "    TRAIN_DIR,\n",
    "    target_size=(299, 299),  \n",
    "    color_mode='rgb',\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary',\n",
    "    subset='validation'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 299, 299, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 149, 149, 32) 864         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 149, 149, 32) 96          conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 149, 149, 32) 0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 147, 147, 32) 9216        activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 147, 147, 32) 96          conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 147, 147, 32) 0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 147, 147, 64) 18432       activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 147, 147, 64) 192         conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 147, 147, 64) 0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 73, 73, 64)   0           activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 73, 73, 80)   5120        max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 73, 73, 80)   240         conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 73, 73, 80)   0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 71, 71, 192)  138240      activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 71, 71, 192)  576         conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 71, 71, 192)  0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 35, 35, 192)  0           activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 35, 35, 64)   12288       max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 35, 35, 64)   192         conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 35, 35, 64)   0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 35, 35, 48)   9216        max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 35, 35, 96)   55296       activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 35, 35, 48)   144         conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 35, 35, 96)   288         conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 35, 35, 48)   0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 35, 35, 96)   0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_1 (AveragePoo (None, 35, 35, 192)  0           max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 35, 35, 64)   12288       max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 35, 35, 64)   76800       activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 35, 35, 96)   82944       activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 35, 35, 32)   6144        average_pooling2d_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 35, 35, 64)   192         conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 35, 35, 64)   192         conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 35, 35, 96)   288         conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 35, 35, 32)   96          conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 35, 35, 64)   0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 35, 35, 64)   0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 35, 35, 96)   0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 35, 35, 32)   0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed0 (Concatenate)            (None, 35, 35, 256)  0           activation_6[0][0]               \n",
      "                                                                 activation_8[0][0]               \n",
      "                                                                 activation_11[0][0]              \n",
      "                                                                 activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 35, 35, 64)   16384       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 35, 35, 64)   192         conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 35, 35, 64)   0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 35, 35, 48)   12288       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 35, 35, 96)   55296       activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 35, 35, 48)   144         conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 35, 35, 96)   288         conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 35, 35, 48)   0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 35, 35, 96)   0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_2 (AveragePoo (None, 35, 35, 256)  0           mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 35, 35, 64)   16384       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 35, 35, 64)   76800       activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 35, 35, 96)   82944       activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 35, 35, 64)   16384       average_pooling2d_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 35, 35, 64)   192         conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 35, 35, 64)   192         conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 35, 35, 96)   288         conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 35, 35, 64)   192         conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 35, 35, 64)   0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 35, 35, 64)   0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 35, 35, 96)   0           batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 35, 35, 64)   0           batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed1 (Concatenate)            (None, 35, 35, 288)  0           activation_13[0][0]              \n",
      "                                                                 activation_15[0][0]              \n",
      "                                                                 activation_18[0][0]              \n",
      "                                                                 activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, 35, 35, 64)   18432       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, 35, 35, 64)   192         conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 35, 35, 64)   0           batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 35, 35, 48)   13824       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, 35, 35, 96)   55296       activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 35, 35, 48)   144         conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, 35, 35, 96)   288         conv2d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 35, 35, 48)   0           batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 35, 35, 96)   0           batch_normalization_24[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_3 (AveragePoo (None, 35, 35, 288)  0           mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 35, 35, 64)   18432       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 35, 35, 64)   76800       activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (None, 35, 35, 96)   82944       activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)              (None, 35, 35, 64)   18432       average_pooling2d_3[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 35, 35, 64)   192         conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, 35, 35, 64)   192         conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNo (None, 35, 35, 96)   288         conv2d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNo (None, 35, 35, 64)   192         conv2d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 35, 35, 64)   0           batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 35, 35, 64)   0           batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 35, 35, 96)   0           batch_normalization_25[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 35, 35, 64)   0           batch_normalization_26[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed2 (Concatenate)            (None, 35, 35, 288)  0           activation_20[0][0]              \n",
      "                                                                 activation_22[0][0]              \n",
      "                                                                 activation_25[0][0]              \n",
      "                                                                 activation_26[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_28 (Conv2D)              (None, 35, 35, 64)   18432       mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNo (None, 35, 35, 64)   192         conv2d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 35, 35, 64)   0           batch_normalization_28[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_29 (Conv2D)              (None, 35, 35, 96)   55296       activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_29 (BatchNo (None, 35, 35, 96)   288         conv2d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 35, 35, 96)   0           batch_normalization_29[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)              (None, 17, 17, 384)  995328      mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_30 (Conv2D)              (None, 17, 17, 96)   82944       activation_29[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNo (None, 17, 17, 384)  1152        conv2d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNo (None, 17, 17, 96)   288         conv2d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 17, 17, 384)  0           batch_normalization_27[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 17, 17, 96)   0           batch_normalization_30[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 17, 17, 288)  0           mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "mixed3 (Concatenate)            (None, 17, 17, 768)  0           activation_27[0][0]              \n",
      "                                                                 activation_30[0][0]              \n",
      "                                                                 max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_35 (Conv2D)              (None, 17, 17, 128)  98304       mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_35 (BatchNo (None, 17, 17, 128)  384         conv2d_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 17, 17, 128)  0           batch_normalization_35[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_36 (Conv2D)              (None, 17, 17, 128)  114688      activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_36 (BatchNo (None, 17, 17, 128)  384         conv2d_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 17, 17, 128)  0           batch_normalization_36[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_32 (Conv2D)              (None, 17, 17, 128)  98304       mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_37 (Conv2D)              (None, 17, 17, 128)  114688      activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_32 (BatchNo (None, 17, 17, 128)  384         conv2d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_37 (BatchNo (None, 17, 17, 128)  384         conv2d_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 17, 17, 128)  0           batch_normalization_32[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 17, 17, 128)  0           batch_normalization_37[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_33 (Conv2D)              (None, 17, 17, 128)  114688      activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_38 (Conv2D)              (None, 17, 17, 128)  114688      activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_33 (BatchNo (None, 17, 17, 128)  384         conv2d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_38 (BatchNo (None, 17, 17, 128)  384         conv2d_38[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 17, 17, 128)  0           batch_normalization_33[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, 17, 17, 128)  0           batch_normalization_38[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_4 (AveragePoo (None, 17, 17, 768)  0           mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_31 (Conv2D)              (None, 17, 17, 192)  147456      mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_34 (Conv2D)              (None, 17, 17, 192)  172032      activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_39 (Conv2D)              (None, 17, 17, 192)  172032      activation_38[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_40 (Conv2D)              (None, 17, 17, 192)  147456      average_pooling2d_4[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_31 (BatchNo (None, 17, 17, 192)  576         conv2d_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_34 (BatchNo (None, 17, 17, 192)  576         conv2d_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_39 (BatchNo (None, 17, 17, 192)  576         conv2d_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_40 (BatchNo (None, 17, 17, 192)  576         conv2d_40[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 17, 17, 192)  0           batch_normalization_31[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 17, 17, 192)  0           batch_normalization_34[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, 17, 17, 192)  0           batch_normalization_39[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, 17, 17, 192)  0           batch_normalization_40[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed4 (Concatenate)            (None, 17, 17, 768)  0           activation_31[0][0]              \n",
      "                                                                 activation_34[0][0]              \n",
      "                                                                 activation_39[0][0]              \n",
      "                                                                 activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_45 (Conv2D)              (None, 17, 17, 160)  122880      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_45 (BatchNo (None, 17, 17, 160)  480         conv2d_45[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, 17, 17, 160)  0           batch_normalization_45[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_46 (Conv2D)              (None, 17, 17, 160)  179200      activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_46 (BatchNo (None, 17, 17, 160)  480         conv2d_46[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, 17, 17, 160)  0           batch_normalization_46[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_42 (Conv2D)              (None, 17, 17, 160)  122880      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_47 (Conv2D)              (None, 17, 17, 160)  179200      activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_42 (BatchNo (None, 17, 17, 160)  480         conv2d_42[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_47 (BatchNo (None, 17, 17, 160)  480         conv2d_47[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, 17, 17, 160)  0           batch_normalization_42[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, 17, 17, 160)  0           batch_normalization_47[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_43 (Conv2D)              (None, 17, 17, 160)  179200      activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_48 (Conv2D)              (None, 17, 17, 160)  179200      activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_43 (BatchNo (None, 17, 17, 160)  480         conv2d_43[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_48 (BatchNo (None, 17, 17, 160)  480         conv2d_48[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, 17, 17, 160)  0           batch_normalization_43[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, 17, 17, 160)  0           batch_normalization_48[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_5 (AveragePoo (None, 17, 17, 768)  0           mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_41 (Conv2D)              (None, 17, 17, 192)  147456      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_44 (Conv2D)              (None, 17, 17, 192)  215040      activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_49 (Conv2D)              (None, 17, 17, 192)  215040      activation_48[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_50 (Conv2D)              (None, 17, 17, 192)  147456      average_pooling2d_5[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_41 (BatchNo (None, 17, 17, 192)  576         conv2d_41[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_44 (BatchNo (None, 17, 17, 192)  576         conv2d_44[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_49 (BatchNo (None, 17, 17, 192)  576         conv2d_49[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_50 (BatchNo (None, 17, 17, 192)  576         conv2d_50[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, 17, 17, 192)  0           batch_normalization_41[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, 17, 17, 192)  0           batch_normalization_44[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_49 (Activation)      (None, 17, 17, 192)  0           batch_normalization_49[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_50 (Activation)      (None, 17, 17, 192)  0           batch_normalization_50[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed5 (Concatenate)            (None, 17, 17, 768)  0           activation_41[0][0]              \n",
      "                                                                 activation_44[0][0]              \n",
      "                                                                 activation_49[0][0]              \n",
      "                                                                 activation_50[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_55 (Conv2D)              (None, 17, 17, 160)  122880      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_55 (BatchNo (None, 17, 17, 160)  480         conv2d_55[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_55 (Activation)      (None, 17, 17, 160)  0           batch_normalization_55[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_56 (Conv2D)              (None, 17, 17, 160)  179200      activation_55[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_56 (BatchNo (None, 17, 17, 160)  480         conv2d_56[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_56 (Activation)      (None, 17, 17, 160)  0           batch_normalization_56[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_52 (Conv2D)              (None, 17, 17, 160)  122880      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_57 (Conv2D)              (None, 17, 17, 160)  179200      activation_56[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_52 (BatchNo (None, 17, 17, 160)  480         conv2d_52[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_57 (BatchNo (None, 17, 17, 160)  480         conv2d_57[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_52 (Activation)      (None, 17, 17, 160)  0           batch_normalization_52[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_57 (Activation)      (None, 17, 17, 160)  0           batch_normalization_57[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_53 (Conv2D)              (None, 17, 17, 160)  179200      activation_52[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_58 (Conv2D)              (None, 17, 17, 160)  179200      activation_57[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_53 (BatchNo (None, 17, 17, 160)  480         conv2d_53[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_58 (BatchNo (None, 17, 17, 160)  480         conv2d_58[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_53 (Activation)      (None, 17, 17, 160)  0           batch_normalization_53[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_58 (Activation)      (None, 17, 17, 160)  0           batch_normalization_58[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_6 (AveragePoo (None, 17, 17, 768)  0           mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_51 (Conv2D)              (None, 17, 17, 192)  147456      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_54 (Conv2D)              (None, 17, 17, 192)  215040      activation_53[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_59 (Conv2D)              (None, 17, 17, 192)  215040      activation_58[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_60 (Conv2D)              (None, 17, 17, 192)  147456      average_pooling2d_6[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_51 (BatchNo (None, 17, 17, 192)  576         conv2d_51[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_54 (BatchNo (None, 17, 17, 192)  576         conv2d_54[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_59 (BatchNo (None, 17, 17, 192)  576         conv2d_59[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_60 (BatchNo (None, 17, 17, 192)  576         conv2d_60[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_51 (Activation)      (None, 17, 17, 192)  0           batch_normalization_51[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_54 (Activation)      (None, 17, 17, 192)  0           batch_normalization_54[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_59 (Activation)      (None, 17, 17, 192)  0           batch_normalization_59[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_60 (Activation)      (None, 17, 17, 192)  0           batch_normalization_60[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed6 (Concatenate)            (None, 17, 17, 768)  0           activation_51[0][0]              \n",
      "                                                                 activation_54[0][0]              \n",
      "                                                                 activation_59[0][0]              \n",
      "                                                                 activation_60[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_65 (Conv2D)              (None, 17, 17, 192)  147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_65 (BatchNo (None, 17, 17, 192)  576         conv2d_65[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_65 (Activation)      (None, 17, 17, 192)  0           batch_normalization_65[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_66 (Conv2D)              (None, 17, 17, 192)  258048      activation_65[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_66 (BatchNo (None, 17, 17, 192)  576         conv2d_66[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_66 (Activation)      (None, 17, 17, 192)  0           batch_normalization_66[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_62 (Conv2D)              (None, 17, 17, 192)  147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_67 (Conv2D)              (None, 17, 17, 192)  258048      activation_66[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_62 (BatchNo (None, 17, 17, 192)  576         conv2d_62[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_67 (BatchNo (None, 17, 17, 192)  576         conv2d_67[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_62 (Activation)      (None, 17, 17, 192)  0           batch_normalization_62[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_67 (Activation)      (None, 17, 17, 192)  0           batch_normalization_67[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_63 (Conv2D)              (None, 17, 17, 192)  258048      activation_62[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_68 (Conv2D)              (None, 17, 17, 192)  258048      activation_67[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_63 (BatchNo (None, 17, 17, 192)  576         conv2d_63[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_68 (BatchNo (None, 17, 17, 192)  576         conv2d_68[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_63 (Activation)      (None, 17, 17, 192)  0           batch_normalization_63[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_68 (Activation)      (None, 17, 17, 192)  0           batch_normalization_68[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_7 (AveragePoo (None, 17, 17, 768)  0           mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_61 (Conv2D)              (None, 17, 17, 192)  147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_64 (Conv2D)              (None, 17, 17, 192)  258048      activation_63[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_69 (Conv2D)              (None, 17, 17, 192)  258048      activation_68[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_70 (Conv2D)              (None, 17, 17, 192)  147456      average_pooling2d_7[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_61 (BatchNo (None, 17, 17, 192)  576         conv2d_61[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_64 (BatchNo (None, 17, 17, 192)  576         conv2d_64[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_69 (BatchNo (None, 17, 17, 192)  576         conv2d_69[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_70 (BatchNo (None, 17, 17, 192)  576         conv2d_70[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_61 (Activation)      (None, 17, 17, 192)  0           batch_normalization_61[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_64 (Activation)      (None, 17, 17, 192)  0           batch_normalization_64[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_69 (Activation)      (None, 17, 17, 192)  0           batch_normalization_69[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_70 (Activation)      (None, 17, 17, 192)  0           batch_normalization_70[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed7 (Concatenate)            (None, 17, 17, 768)  0           activation_61[0][0]              \n",
      "                                                                 activation_64[0][0]              \n",
      "                                                                 activation_69[0][0]              \n",
      "                                                                 activation_70[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_73 (Conv2D)              (None, 17, 17, 192)  147456      mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_73 (BatchNo (None, 17, 17, 192)  576         conv2d_73[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_73 (Activation)      (None, 17, 17, 192)  0           batch_normalization_73[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_74 (Conv2D)              (None, 17, 17, 192)  258048      activation_73[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_74 (BatchNo (None, 17, 17, 192)  576         conv2d_74[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_74 (Activation)      (None, 17, 17, 192)  0           batch_normalization_74[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_71 (Conv2D)              (None, 17, 17, 192)  147456      mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_75 (Conv2D)              (None, 17, 17, 192)  258048      activation_74[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_71 (BatchNo (None, 17, 17, 192)  576         conv2d_71[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_75 (BatchNo (None, 17, 17, 192)  576         conv2d_75[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_71 (Activation)      (None, 17, 17, 192)  0           batch_normalization_71[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_75 (Activation)      (None, 17, 17, 192)  0           batch_normalization_75[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_72 (Conv2D)              (None, 8, 8, 320)    552960      activation_71[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_76 (Conv2D)              (None, 8, 8, 192)    331776      activation_75[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_72 (BatchNo (None, 8, 8, 320)    960         conv2d_72[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_76 (BatchNo (None, 8, 8, 192)    576         conv2d_76[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_72 (Activation)      (None, 8, 8, 320)    0           batch_normalization_72[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_76 (Activation)      (None, 8, 8, 192)    0           batch_normalization_76[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)  (None, 8, 8, 768)    0           mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "mixed8 (Concatenate)            (None, 8, 8, 1280)   0           activation_72[0][0]              \n",
      "                                                                 activation_76[0][0]              \n",
      "                                                                 max_pooling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_81 (Conv2D)              (None, 8, 8, 448)    573440      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_81 (BatchNo (None, 8, 8, 448)    1344        conv2d_81[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_81 (Activation)      (None, 8, 8, 448)    0           batch_normalization_81[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_78 (Conv2D)              (None, 8, 8, 384)    491520      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_82 (Conv2D)              (None, 8, 8, 384)    1548288     activation_81[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_78 (BatchNo (None, 8, 8, 384)    1152        conv2d_78[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_82 (BatchNo (None, 8, 8, 384)    1152        conv2d_82[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_78 (Activation)      (None, 8, 8, 384)    0           batch_normalization_78[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_82 (Activation)      (None, 8, 8, 384)    0           batch_normalization_82[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_79 (Conv2D)              (None, 8, 8, 384)    442368      activation_78[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_80 (Conv2D)              (None, 8, 8, 384)    442368      activation_78[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_83 (Conv2D)              (None, 8, 8, 384)    442368      activation_82[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_84 (Conv2D)              (None, 8, 8, 384)    442368      activation_82[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_8 (AveragePoo (None, 8, 8, 1280)   0           mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_77 (Conv2D)              (None, 8, 8, 320)    409600      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_79 (BatchNo (None, 8, 8, 384)    1152        conv2d_79[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_80 (BatchNo (None, 8, 8, 384)    1152        conv2d_80[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_83 (BatchNo (None, 8, 8, 384)    1152        conv2d_83[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_84 (BatchNo (None, 8, 8, 384)    1152        conv2d_84[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_85 (Conv2D)              (None, 8, 8, 192)    245760      average_pooling2d_8[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_77 (BatchNo (None, 8, 8, 320)    960         conv2d_77[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_79 (Activation)      (None, 8, 8, 384)    0           batch_normalization_79[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_80 (Activation)      (None, 8, 8, 384)    0           batch_normalization_80[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_83 (Activation)      (None, 8, 8, 384)    0           batch_normalization_83[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_84 (Activation)      (None, 8, 8, 384)    0           batch_normalization_84[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_85 (BatchNo (None, 8, 8, 192)    576         conv2d_85[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_77 (Activation)      (None, 8, 8, 320)    0           batch_normalization_77[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed9_0 (Concatenate)          (None, 8, 8, 768)    0           activation_79[0][0]              \n",
      "                                                                 activation_80[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 8, 8, 768)    0           activation_83[0][0]              \n",
      "                                                                 activation_84[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_85 (Activation)      (None, 8, 8, 192)    0           batch_normalization_85[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed9 (Concatenate)            (None, 8, 8, 2048)   0           activation_77[0][0]              \n",
      "                                                                 mixed9_0[0][0]                   \n",
      "                                                                 concatenate_1[0][0]              \n",
      "                                                                 activation_85[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_90 (Conv2D)              (None, 8, 8, 448)    917504      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_90 (BatchNo (None, 8, 8, 448)    1344        conv2d_90[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_90 (Activation)      (None, 8, 8, 448)    0           batch_normalization_90[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_87 (Conv2D)              (None, 8, 8, 384)    786432      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_91 (Conv2D)              (None, 8, 8, 384)    1548288     activation_90[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_87 (BatchNo (None, 8, 8, 384)    1152        conv2d_87[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_91 (BatchNo (None, 8, 8, 384)    1152        conv2d_91[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_87 (Activation)      (None, 8, 8, 384)    0           batch_normalization_87[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_91 (Activation)      (None, 8, 8, 384)    0           batch_normalization_91[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_88 (Conv2D)              (None, 8, 8, 384)    442368      activation_87[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_89 (Conv2D)              (None, 8, 8, 384)    442368      activation_87[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_92 (Conv2D)              (None, 8, 8, 384)    442368      activation_91[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_93 (Conv2D)              (None, 8, 8, 384)    442368      activation_91[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_9 (AveragePoo (None, 8, 8, 2048)   0           mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_86 (Conv2D)              (None, 8, 8, 320)    655360      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_88 (BatchNo (None, 8, 8, 384)    1152        conv2d_88[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_89 (BatchNo (None, 8, 8, 384)    1152        conv2d_89[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_92 (BatchNo (None, 8, 8, 384)    1152        conv2d_92[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_93 (BatchNo (None, 8, 8, 384)    1152        conv2d_93[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_94 (Conv2D)              (None, 8, 8, 192)    393216      average_pooling2d_9[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_86 (BatchNo (None, 8, 8, 320)    960         conv2d_86[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_88 (Activation)      (None, 8, 8, 384)    0           batch_normalization_88[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_89 (Activation)      (None, 8, 8, 384)    0           batch_normalization_89[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_92 (Activation)      (None, 8, 8, 384)    0           batch_normalization_92[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_93 (Activation)      (None, 8, 8, 384)    0           batch_normalization_93[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_94 (BatchNo (None, 8, 8, 192)    576         conv2d_94[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_86 (Activation)      (None, 8, 8, 320)    0           batch_normalization_86[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed9_1 (Concatenate)          (None, 8, 8, 768)    0           activation_88[0][0]              \n",
      "                                                                 activation_89[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 8, 8, 768)    0           activation_92[0][0]              \n",
      "                                                                 activation_93[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_94 (Activation)      (None, 8, 8, 192)    0           batch_normalization_94[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed10 (Concatenate)           (None, 8, 8, 2048)   0           activation_86[0][0]              \n",
      "                                                                 mixed9_1[0][0]                   \n",
      "                                                                 concatenate_2[0][0]              \n",
      "                                                                 activation_94[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_1 (Glo (None, 2048)         0           mixed10[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 2048)         4196352     global_average_pooling2d_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 1)            2049        dense_1[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 26,001,185\n",
      "Trainable params: 25,966,753\n",
      "Non-trainable params: 34,432\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_tensor = Input(shape=(299, 299,3))  # this assumes K.image_data_format() == 'channels_last'\n",
    "base_model = InceptionV3(input_tensor=input_tensor, weights='imagenet', include_top=False, pooling='avg')\n",
    "# add a global spatial average pooling layer\n",
    "x = base_model.output\n",
    "x = Dense(2048, activation = 'relu')(x)\n",
    "predictions = Dense(1, activation = 'sigmoid')(x)\n",
    "\n",
    "#for layer in base_model.layers:\n",
    "#    layer.trainable = False\n",
    "\n",
    "# this is the model we will train\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def mean_xentropy(y_true, y_pred):\n",
    "#    bce = tf.keras.losses.BinaryCrossentropy(from_logits=True)  #porque ya viene de un sigmoide\n",
    "#    return tf.reduce_mean(bce(y_true, y_pred))  \n",
    "\n",
    "#for layer in base_model.layers:\n",
    "#    layer.trainable = False\n",
    "\n",
    "optimizer = tf.keras.optimizers.RMSprop(learning_rate = learning_rate, decay = decay)\n",
    "\n",
    "#model.compile(optimizer='rmsprop', loss=mean_xentropy, metrics = ['accuracy'])\n",
    "model.compile(optimizer=optimizer, loss=tf.keras.losses.BinaryCrossentropy(), metrics = ['accuracy',tf.keras.metrics.AUC()])\n",
    "\n",
    "model.load_weights('inceptionV3_keras_2_1.h5') # estos son los pesos del warming up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = ModelCheckpoint('inceptionV3_keras_2_4.h5', monitor='val_auc', verbose=1, save_best_only = True, mode='auto')\n",
    "early_stop = EarlyStopping(monitor='val_auc', min_delta=0, patience=200, verbose=1, \n",
    "                           mode='auto', baseline=None, restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "1420/1420 [==============================] - 1702s 1s/step - loss: 0.1818 - accuracy: 0.9251 - auc: 0.9715 - val_loss: 0.8864 - val_accuracy: 0.8060 - val_auc: 0.9619\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.88639, saving model to inceptionV3_keras_2_3.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/keras/engine/saving.py:165: UserWarning: TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file.You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "  'TensorFlow optimizers do not '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/200\n",
      "1420/1420 [==============================] - 1613s 1s/step - loss: 0.1834 - accuracy: 0.9248 - auc: 0.9566 - val_loss: 0.8857 - val_accuracy: 0.8072 - val_auc: 0.9538\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.88639 to 0.88565, saving model to inceptionV3_keras_2_3.h5\n",
      "Epoch 3/200\n",
      "1420/1420 [==============================] - 2317s 2s/step - loss: 0.1768 - accuracy: 0.9303 - auc: 0.9517 - val_loss: 0.9486 - val_accuracy: 0.8064 - val_auc: 0.9507\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.88565\n",
      "Epoch 4/200\n",
      "1420/1420 [==============================] - 1829s 1s/step - loss: 0.1740 - accuracy: 0.9301 - auc: 0.9496 - val_loss: 0.4290 - val_accuracy: 0.8054 - val_auc: 0.9488\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.88565 to 0.42902, saving model to inceptionV3_keras_2_3.h5\n",
      "Epoch 5/200\n",
      "1420/1420 [==============================] - 1628s 1s/step - loss: 0.1743 - accuracy: 0.9294 - auc: 0.9483 - val_loss: 1.2980 - val_accuracy: 0.8092 - val_auc: 0.9480\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.42902\n",
      "Epoch 6/200\n",
      "1420/1420 [==============================] - 1597s 1s/step - loss: 0.1675 - accuracy: 0.9331 - auc: 0.9476 - val_loss: 0.7406 - val_accuracy: 0.8109 - val_auc: 0.9474\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.42902\n",
      "Epoch 7/200\n",
      "1420/1420 [==============================] - 1737s 1s/step - loss: 0.1704 - accuracy: 0.9312 - auc: 0.9472 - val_loss: 0.9772 - val_accuracy: 0.8046 - val_auc: 0.9470\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.42902\n",
      "Epoch 8/200\n",
      "1420/1420 [==============================] - 1685s 1s/step - loss: 0.1659 - accuracy: 0.9328 - auc: 0.9469 - val_loss: 0.8451 - val_accuracy: 0.8112 - val_auc: 0.9469\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.42902\n",
      "Epoch 9/200\n",
      "1420/1420 [==============================] - 1620s 1s/step - loss: 0.1625 - accuracy: 0.9347 - auc: 0.9469 - val_loss: 0.7929 - val_accuracy: 0.8098 - val_auc: 0.9469\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.42902\n",
      "Epoch 10/200\n",
      "1420/1420 [==============================] - 1597s 1s/step - loss: 0.1642 - accuracy: 0.9344 - auc: 0.9468 - val_loss: 0.7433 - val_accuracy: 0.8079 - val_auc: 0.9467\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.42902\n",
      "Epoch 11/200\n",
      "1420/1420 [==============================] - 1634s 1s/step - loss: 0.1598 - accuracy: 0.9362 - auc: 0.9467 - val_loss: 0.1439 - val_accuracy: 0.8049 - val_auc: 0.9467\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.42902 to 0.14390, saving model to inceptionV3_keras_2_3.h5\n",
      "Epoch 12/200\n",
      "1420/1420 [==============================] - 1653s 1s/step - loss: 0.1556 - accuracy: 0.9378 - auc: 0.9467 - val_loss: 1.0112 - val_accuracy: 0.8060 - val_auc: 0.9468\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.14390\n",
      "Epoch 13/200\n",
      "1420/1420 [==============================] - 1953s 1s/step - loss: 0.1525 - accuracy: 0.9397 - auc: 0.9469 - val_loss: 0.7027 - val_accuracy: 0.8045 - val_auc: 0.9470\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.14390\n",
      "Epoch 14/200\n",
      "1420/1420 [==============================] - 1795s 1s/step - loss: 0.1516 - accuracy: 0.9398 - auc: 0.9470 - val_loss: 0.6233 - val_accuracy: 0.8057 - val_auc: 0.9472\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.14390\n",
      "Epoch 15/200\n",
      "1420/1420 [==============================] - 1937s 1s/step - loss: 0.1504 - accuracy: 0.9401 - auc: 0.9472 - val_loss: 0.2810 - val_accuracy: 0.8086 - val_auc: 0.9473\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.14390\n",
      "Epoch 16/200\n",
      "1420/1420 [==============================] - 1786s 1s/step - loss: 0.1521 - accuracy: 0.9385 - auc: 0.9473 - val_loss: 0.5030 - val_accuracy: 0.8040 - val_auc: 0.9473\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.14390\n",
      "Epoch 17/200\n",
      "1420/1420 [==============================] - 1901s 1s/step - loss: 0.1471 - accuracy: 0.9419 - auc: 0.9474 - val_loss: 1.0842 - val_accuracy: 0.8041 - val_auc: 0.9474\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.14390\n",
      "Epoch 18/200\n",
      "1420/1420 [==============================] - 1777s 1s/step - loss: 0.1501 - accuracy: 0.9405 - auc: 0.9475 - val_loss: 0.4991 - val_accuracy: 0.8085 - val_auc: 0.9475\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.14390\n",
      "Epoch 19/200\n",
      "1420/1420 [==============================] - 1862s 1s/step - loss: 0.1474 - accuracy: 0.9415 - auc: 0.9476 - val_loss: 0.7832 - val_accuracy: 0.8078 - val_auc: 0.9476\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.14390\n",
      "Epoch 20/200\n",
      "1420/1420 [==============================] - 1786s 1s/step - loss: 0.1446 - accuracy: 0.9419 - auc: 0.9477 - val_loss: 0.1888 - val_accuracy: 0.8104 - val_auc: 0.9478\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.14390\n",
      "Epoch 21/200\n",
      "1420/1420 [==============================] - 1869s 1s/step - loss: 0.1472 - accuracy: 0.9424 - auc: 0.9479 - val_loss: 1.2181 - val_accuracy: 0.7984 - val_auc: 0.9479\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.14390\n",
      "Epoch 22/200\n",
      "1420/1420 [==============================] - 1823s 1s/step - loss: 0.1463 - accuracy: 0.9415 - auc: 0.9480 - val_loss: 0.4184 - val_accuracy: 0.8051 - val_auc: 0.9480\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.14390\n",
      "Epoch 23/200\n",
      "1420/1420 [==============================] - 1853s 1s/step - loss: 0.1416 - accuracy: 0.9449 - auc: 0.9481 - val_loss: 1.2293 - val_accuracy: 0.8019 - val_auc: 0.9481\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.14390\n",
      "Epoch 24/200\n",
      "1420/1420 [==============================] - 1922s 1s/step - loss: 0.1386 - accuracy: 0.9457 - auc: 0.9482 - val_loss: 1.2349 - val_accuracy: 0.8091 - val_auc: 0.9483\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.14390\n",
      "Epoch 25/200\n",
      "1420/1420 [==============================] - 1791s 1s/step - loss: 0.1373 - accuracy: 0.9456 - auc: 0.9483 - val_loss: 0.6496 - val_accuracy: 0.8096 - val_auc: 0.9484\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.14390\n",
      "Epoch 26/200\n",
      "1420/1420 [==============================] - 1903s 1s/step - loss: 0.1349 - accuracy: 0.9464 - auc: 0.9485 - val_loss: 0.9379 - val_accuracy: 0.8082 - val_auc: 0.9485\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.14390\n",
      "Epoch 27/200\n",
      "1420/1420 [==============================] - 1781s 1s/step - loss: 0.1400 - accuracy: 0.9448 - auc: 0.9486 - val_loss: 0.8528 - val_accuracy: 0.8017 - val_auc: 0.9486\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.14390\n",
      "Epoch 28/200\n",
      "1420/1420 [==============================] - 1913s 1s/step - loss: 0.1382 - accuracy: 0.9448 - auc: 0.9487 - val_loss: 1.3254 - val_accuracy: 0.8052 - val_auc: 0.9488\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.14390\n",
      "Epoch 29/200\n",
      "1420/1420 [==============================] - 1800s 1s/step - loss: 0.1342 - accuracy: 0.9467 - auc: 0.9488 - val_loss: 0.8662 - val_accuracy: 0.8063 - val_auc: 0.9489\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.14390\n",
      "Epoch 30/200\n",
      "1420/1420 [==============================] - 1918s 1s/step - loss: 0.1373 - accuracy: 0.9440 - auc: 0.9489 - val_loss: 0.9495 - val_accuracy: 0.8066 - val_auc: 0.9489\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.14390\n",
      "Epoch 31/200\n",
      "1420/1420 [==============================] - 1795s 1s/step - loss: 0.1340 - accuracy: 0.9471 - auc: 0.9490 - val_loss: 0.5780 - val_accuracy: 0.8089 - val_auc: 0.9491\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.14390\n",
      "Epoch 32/200\n",
      "1420/1420 [==============================] - 1960s 1s/step - loss: 0.1323 - accuracy: 0.9480 - auc: 0.9491 - val_loss: 0.5802 - val_accuracy: 0.8039 - val_auc: 0.9491\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.14390\n",
      "Epoch 33/200\n",
      "1420/1420 [==============================] - 2555s 2s/step - loss: 0.1266 - accuracy: 0.9500 - auc: 0.9492 - val_loss: 0.6715 - val_accuracy: 0.8038 - val_auc: 0.9493\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.14390\n",
      "Epoch 34/200\n",
      "1420/1420 [==============================] - 2611s 2s/step - loss: 0.1296 - accuracy: 0.9492 - auc: 0.9493 - val_loss: 0.8891 - val_accuracy: 0.8022 - val_auc: 0.9494\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.14390\n",
      "Epoch 35/200\n",
      "1420/1420 [==============================] - 2568s 2s/step - loss: 0.1298 - accuracy: 0.9492 - auc: 0.9494 - val_loss: 0.8596 - val_accuracy: 0.8041 - val_auc: 0.9495\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.14390\n",
      "Epoch 36/200\n",
      "1420/1420 [==============================] - 2564s 2s/step - loss: 0.1280 - accuracy: 0.9497 - auc: 0.9496 - val_loss: 0.3556 - val_accuracy: 0.8023 - val_auc: 0.9496\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.14390\n",
      "Epoch 37/200\n",
      "1420/1420 [==============================] - 2553s 2s/step - loss: 0.1320 - accuracy: 0.9496 - auc: 0.9496 - val_loss: 0.8773 - val_accuracy: 0.8053 - val_auc: 0.9497\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.14390\n",
      "Epoch 38/200\n",
      "1420/1420 [==============================] - 2480s 2s/step - loss: 0.1268 - accuracy: 0.9513 - auc: 0.9497 - val_loss: 0.2582 - val_accuracy: 0.8059 - val_auc: 0.9497\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.14390\n",
      "Epoch 39/200\n",
      "1420/1420 [==============================] - 1791s 1s/step - loss: 0.1290 - accuracy: 0.9500 - auc: 0.9498 - val_loss: 0.6088 - val_accuracy: 0.8006 - val_auc: 0.9498\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.14390\n",
      "Epoch 40/200\n",
      "1420/1420 [==============================] - 1901s 1s/step - loss: 0.1275 - accuracy: 0.9490 - auc: 0.9499 - val_loss: 1.3431 - val_accuracy: 0.8039 - val_auc: 0.9499\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.14390\n",
      "Epoch 41/200\n",
      "1420/1420 [==============================] - 1797s 1s/step - loss: 0.1300 - accuracy: 0.9495 - auc: 0.9500 - val_loss: 0.5799 - val_accuracy: 0.8046 - val_auc: 0.9500\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.14390\n",
      "Epoch 42/200\n",
      "1420/1420 [==============================] - 1911s 1s/step - loss: 0.1230 - accuracy: 0.9526 - auc: 0.9501 - val_loss: 0.7613 - val_accuracy: 0.8096 - val_auc: 0.9501\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.14390\n",
      "Epoch 43/200\n",
      "1420/1420 [==============================] - 1823s 1s/step - loss: 0.1215 - accuracy: 0.9524 - auc: 0.9502 - val_loss: 0.3278 - val_accuracy: 0.8032 - val_auc: 0.9502\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.14390\n",
      "Epoch 44/200\n",
      "1420/1420 [==============================] - 1900s 1s/step - loss: 0.1246 - accuracy: 0.9515 - auc: 0.9503 - val_loss: 0.8916 - val_accuracy: 0.8059 - val_auc: 0.9503\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.14390\n",
      "Epoch 45/200\n",
      "1420/1420 [==============================] - 1896s 1s/step - loss: 0.1206 - accuracy: 0.9534 - auc: 0.9503 - val_loss: 0.6315 - val_accuracy: 0.8057 - val_auc: 0.9504\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.14390\n",
      "Epoch 46/200\n",
      " 399/1420 [=======>......................] - ETA: 19:29 - loss: 0.1226 - accuracy: 0.9524 - auc: 0.9502"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-d3ee8335ba67>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m                     \u001b[0mvalidation_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mval_generator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m                     \u001b[0mvalidation_steps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m11364\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m                     \u001b[0mcallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mearly_stop\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m                    )\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1730\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1731\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1732\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1733\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    218\u001b[0m                                             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m                                             \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 220\u001b[0;31m                                             reset_metrics=False)\n\u001b[0m\u001b[1;32m    221\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight, reset_metrics)\u001b[0m\n\u001b[1;32m   1512\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1514\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1515\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1516\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3733\u001b[0m     return nest.pack_sequence_as(\n\u001b[1;32m   3734\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_outputs_structure\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3735\u001b[0;31m         \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3736\u001b[0m         expand_composites=True)\n\u001b[1;32m   3737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/keras/backend.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   3733\u001b[0m     return nest.pack_sequence_as(\n\u001b[1;32m   3734\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_outputs_structure\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3735\u001b[0;31m         \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3736\u001b[0m         expand_composites=True)\n\u001b[1;32m   3737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py\u001b[0m in \u001b[0;36m_numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    906\u001b[0m     \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    907\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 908\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    909\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    910\u001b[0m       \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# train the model on the new data for a few epochs\n",
    "\n",
    "model.fit_generator(train_generator,\n",
    "                    steps_per_epoch = 45463 // batch_size,\n",
    "                    epochs = num_epochs,\n",
    "                    validation_data = val_generator,\n",
    "                    validation_steps = 11364 // batch_size,\n",
    "                    callbacks = [checkpoint, early_stop]\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "1420/1420 [==============================] - 2906s 2s/step - loss: 0.1858 - accuracy: 0.9262 - auc: 0.9722 - val_loss: 0.3070 - val_accuracy: 0.8099 - val_auc: 0.9546\n",
      "\n",
      "Epoch 00001: val_auc improved from inf to 0.95462, saving model to inceptionV3_keras_2_4.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/keras/engine/saving.py:165: UserWarning: TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file.You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "  'TensorFlow optimizers do not '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/200\n",
      " 251/1420 [====>.........................] - ETA: 28:28 - loss: 0.1842 - accuracy: 0.9246 - auc: 0.9426"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-8ebc41f45781>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m                     \u001b[0mvalidation_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mval_generator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m                     \u001b[0mvalidation_steps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m11364\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m                     \u001b[0mcallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mearly_stop\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m                    )\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1730\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1731\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1732\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1733\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    218\u001b[0m                                             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m                                             \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 220\u001b[0;31m                                             reset_metrics=False)\n\u001b[0m\u001b[1;32m    221\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight, reset_metrics)\u001b[0m\n\u001b[1;32m   1512\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1514\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1515\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1516\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3725\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3726\u001b[0m       \u001b[0mconverted_inputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3727\u001b[0;31m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mconverted_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3728\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3729\u001b[0m     \u001b[0;31m# EagerTensor.numpy() will often make a copy to ensure memory safety.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1549\u001b[0m       \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mFor\u001b[0m \u001b[0minvalid\u001b[0m \u001b[0mpositional\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mkeyword\u001b[0m \u001b[0margument\u001b[0m \u001b[0mcombinations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1550\u001b[0m     \"\"\"\n\u001b[0;32m-> 1551\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1552\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1553\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1589\u001b[0m       raise TypeError(\"Keyword arguments {} unknown. Expected {}.\".format(\n\u001b[1;32m   1590\u001b[0m           list(kwargs.keys()), list(self._arg_keywords)))\n\u001b[0;32m-> 1591\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1592\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1593\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1690\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1691\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1692\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1693\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1694\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    543\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"executor_type\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"config_proto\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 545\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[1;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m                                                num_outputs)\n\u001b[0m\u001b[1;32m     62\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# train the whole model on the new data for more epochs\n",
    "\n",
    "model.fit_generator(train_generator,\n",
    "                    steps_per_epoch = 45463 // batch_size,\n",
    "                    epochs = num_epochs,\n",
    "                    validation_data = val_generator,\n",
    "                    validation_steps = 11364 // batch_size,\n",
    "                    callbacks = [checkpoint, early_stop]\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Evaluando en TEST de Kaggle de esta gente**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8790 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "\n",
    "test_datagen = ImageDataGenerator(samplewise_center = True, rescale=1./255)\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "                                                    TEST_DIR,\n",
    "                                                    target_size=(299, 299),  \n",
    "                                                    color_mode='rgb',\n",
    "                                                    batch_size=batch_size,\n",
    "                                                    class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.38943278789520264, 0.9131968021392822, 0.9436360597610474]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate_generator(test_generator) # inceptionV3_keras_2_4.h5, el que tiene val_auc maximo a 201 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.13143935799598694, 0.9142206907272339, 0.9434365034103394]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate_generator(test_generator) # inceptionV3_keras_2_3.h5, el que tiene val_loss minimo, 210 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['loss', 'accuracy', 'auc_1']"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.metrics_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Evaluando en Messidor2**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1748 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "\n",
    "test_datagen = ImageDataGenerator(samplewise_center = True, rescale=1./255)\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "                                                    MESSIDOR2_DIR,\n",
    "                                                    target_size=(299, 299),  \n",
    "                                                    color_mode='rgb',\n",
    "                                                    batch_size=batch_size,\n",
    "                                                    class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.5602930784225464, 0.8758581280708313, 0.9501880407333374]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate_generator(test_generator) # inceptionV3_keras_2_2.h5, el que tiene val_auc maximo a 200 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.2662986218929291, 0.8764302134513855, 0.9305860996246338]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate_generator(test_generator) # inceptionV3_keras_2_3.h5, el que tiene val_loss minimo a 210 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.6204572916030884, 0.8752860426902771, 0.942309558391571]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate_generator(test_generator) # inceptionV3_keras_2_4.h5, el que tiene val_loss minimo a 201 epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluando con Scikit Learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1368 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "\n",
    "test_datagen = ImageDataGenerator(samplewise_center = True, rescale=1./255)\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "                                                    '/home/stoledoc/work/datanfs/stoledoc/jama16-retina-replication-master/data/messidor/0/',\n",
    "                                                    #'/home/stoledoc/work/datanfs/stoledoc/jama16-retina-replication-master/data/eyepacs_for_test/0/',\n",
    "                                                    target_size=(299, 299),  \n",
    "                                                    color_mode='rgb',\n",
    "                                                    batch_size=batch_size,\n",
    "                                                    class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicciones_0 = model.predict(test_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1039591"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicciones_0.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 380 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "\n",
    "test_datagen = ImageDataGenerator(samplewise_center = True, rescale=1./255)\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "                                                    '/home/stoledoc/work/datanfs/stoledoc/jama16-retina-replication-master/data/messidor/1/',\n",
    "                                                    #'/home/stoledoc/work/datanfs/stoledoc/jama16-retina-replication-master/data/eyepacs_for_test/1/',\n",
    "                                                    target_size=(299, 299),  \n",
    "                                                    color_mode='rgb',\n",
    "                                                    batch_size=batch_size,\n",
    "                                                    class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicciones_1 = model.predict_generator(test_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6618212"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicciones_1.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#messidor\n",
    "y_true_0 = np.zeros([1368,])\n",
    "y_true_1 = np.ones([380,])\n",
    "#eyepacs\n",
    "#y_true_0 = np.zeros([8096,])\n",
    "#y_true_1 = np.ones([694,])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicciones = np.concatenate([predicciones_0, predicciones_1])\n",
    "y_true = np.concatenate([y_true_0, y_true_1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8805978762696216"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_true, predicciones) # inceptionV3_keras_2_3.h5, el que tiene val_loss minimo a 210 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8791685903354878"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_true, predicciones) # inceptionV3_keras_2_4.h5, el que tiene val_auc maximo a 201 epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora la matriz de confusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.5\n",
    "for i in range(len(predicciones)):\n",
    "    if predicciones[i] < threshold:\n",
    "        predicciones[i] = 0\n",
    "    else:\n",
    "        predicciones[i] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1280,   88],\n",
       "       [ 127,  253]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_true, predicciones) # inceptionV3_keras_2_2.h5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1279,   89],\n",
       "       [ 127,  253]])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_true, predicciones) # inceptionV3_keras_2_3.h5, el que tiene val_loss minimo a 210 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               precision    recall  f1-score   support\n",
      "\n",
      "non-referable       0.91      0.94      0.92      1368\n",
      "    referable       0.74      0.67      0.70       380\n",
      "\n",
      "     accuracy                           0.88      1748\n",
      "    macro avg       0.83      0.80      0.81      1748\n",
      " weighted avg       0.87      0.88      0.87      1748\n",
      "\n"
     ]
    }
   ],
   "source": [
    "target_names = ['non-referable', 'referable']\n",
    "print(classification_report(y_true, predicciones, target_names=target_names)) # inceptionV3_keras_2_2.h5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               precision    recall  f1-score   support\n",
      "\n",
      "non-referable       0.91      0.93      0.92      1368\n",
      "    referable       0.74      0.67      0.70       380\n",
      "\n",
      "     accuracy                           0.88      1748\n",
      "    macro avg       0.82      0.80      0.81      1748\n",
      " weighted avg       0.87      0.88      0.87      1748\n",
      "\n"
     ]
    }
   ],
   "source": [
    "target_names = ['non-referable', 'referable'] \n",
    "print(classification_report(y_true, predicciones, target_names=target_names)) # inceptionV3_keras_2_3.h5, el que tiene val_loss minimo a 210 epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ahora a sacar caracteristicas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 299, 299, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 149, 149, 32) 864         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 149, 149, 32) 96          conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 149, 149, 32) 0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 147, 147, 32) 9216        activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 147, 147, 32) 96          conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 147, 147, 32) 0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 147, 147, 64) 18432       activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 147, 147, 64) 192         conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 147, 147, 64) 0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 73, 73, 64)   0           activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 73, 73, 80)   5120        max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 73, 73, 80)   240         conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 73, 73, 80)   0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 71, 71, 192)  138240      activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 71, 71, 192)  576         conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 71, 71, 192)  0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 35, 35, 192)  0           activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 35, 35, 64)   12288       max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 35, 35, 64)   192         conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 35, 35, 64)   0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 35, 35, 48)   9216        max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 35, 35, 96)   55296       activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 35, 35, 48)   144         conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 35, 35, 96)   288         conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 35, 35, 48)   0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 35, 35, 96)   0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_1 (AveragePoo (None, 35, 35, 192)  0           max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 35, 35, 64)   12288       max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 35, 35, 64)   76800       activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 35, 35, 96)   82944       activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 35, 35, 32)   6144        average_pooling2d_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 35, 35, 64)   192         conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 35, 35, 64)   192         conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 35, 35, 96)   288         conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 35, 35, 32)   96          conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 35, 35, 64)   0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 35, 35, 64)   0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 35, 35, 96)   0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 35, 35, 32)   0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed0 (Concatenate)            (None, 35, 35, 256)  0           activation_6[0][0]               \n",
      "                                                                 activation_8[0][0]               \n",
      "                                                                 activation_11[0][0]              \n",
      "                                                                 activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 35, 35, 64)   16384       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 35, 35, 64)   192         conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 35, 35, 64)   0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 35, 35, 48)   12288       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 35, 35, 96)   55296       activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 35, 35, 48)   144         conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 35, 35, 96)   288         conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 35, 35, 48)   0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 35, 35, 96)   0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_2 (AveragePoo (None, 35, 35, 256)  0           mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 35, 35, 64)   16384       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 35, 35, 64)   76800       activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 35, 35, 96)   82944       activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 35, 35, 64)   16384       average_pooling2d_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 35, 35, 64)   192         conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 35, 35, 64)   192         conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 35, 35, 96)   288         conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 35, 35, 64)   192         conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 35, 35, 64)   0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 35, 35, 64)   0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 35, 35, 96)   0           batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 35, 35, 64)   0           batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed1 (Concatenate)            (None, 35, 35, 288)  0           activation_13[0][0]              \n",
      "                                                                 activation_15[0][0]              \n",
      "                                                                 activation_18[0][0]              \n",
      "                                                                 activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, 35, 35, 64)   18432       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, 35, 35, 64)   192         conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 35, 35, 64)   0           batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 35, 35, 48)   13824       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, 35, 35, 96)   55296       activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 35, 35, 48)   144         conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, 35, 35, 96)   288         conv2d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 35, 35, 48)   0           batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 35, 35, 96)   0           batch_normalization_24[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_3 (AveragePoo (None, 35, 35, 288)  0           mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 35, 35, 64)   18432       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 35, 35, 64)   76800       activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (None, 35, 35, 96)   82944       activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)              (None, 35, 35, 64)   18432       average_pooling2d_3[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 35, 35, 64)   192         conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, 35, 35, 64)   192         conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNo (None, 35, 35, 96)   288         conv2d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNo (None, 35, 35, 64)   192         conv2d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 35, 35, 64)   0           batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 35, 35, 64)   0           batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 35, 35, 96)   0           batch_normalization_25[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 35, 35, 64)   0           batch_normalization_26[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed2 (Concatenate)            (None, 35, 35, 288)  0           activation_20[0][0]              \n",
      "                                                                 activation_22[0][0]              \n",
      "                                                                 activation_25[0][0]              \n",
      "                                                                 activation_26[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_28 (Conv2D)              (None, 35, 35, 64)   18432       mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNo (None, 35, 35, 64)   192         conv2d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 35, 35, 64)   0           batch_normalization_28[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_29 (Conv2D)              (None, 35, 35, 96)   55296       activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_29 (BatchNo (None, 35, 35, 96)   288         conv2d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 35, 35, 96)   0           batch_normalization_29[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)              (None, 17, 17, 384)  995328      mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_30 (Conv2D)              (None, 17, 17, 96)   82944       activation_29[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNo (None, 17, 17, 384)  1152        conv2d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNo (None, 17, 17, 96)   288         conv2d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 17, 17, 384)  0           batch_normalization_27[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 17, 17, 96)   0           batch_normalization_30[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 17, 17, 288)  0           mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "mixed3 (Concatenate)            (None, 17, 17, 768)  0           activation_27[0][0]              \n",
      "                                                                 activation_30[0][0]              \n",
      "                                                                 max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_35 (Conv2D)              (None, 17, 17, 128)  98304       mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_35 (BatchNo (None, 17, 17, 128)  384         conv2d_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 17, 17, 128)  0           batch_normalization_35[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_36 (Conv2D)              (None, 17, 17, 128)  114688      activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_36 (BatchNo (None, 17, 17, 128)  384         conv2d_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 17, 17, 128)  0           batch_normalization_36[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_32 (Conv2D)              (None, 17, 17, 128)  98304       mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_37 (Conv2D)              (None, 17, 17, 128)  114688      activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_32 (BatchNo (None, 17, 17, 128)  384         conv2d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_37 (BatchNo (None, 17, 17, 128)  384         conv2d_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 17, 17, 128)  0           batch_normalization_32[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 17, 17, 128)  0           batch_normalization_37[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_33 (Conv2D)              (None, 17, 17, 128)  114688      activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_38 (Conv2D)              (None, 17, 17, 128)  114688      activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_33 (BatchNo (None, 17, 17, 128)  384         conv2d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_38 (BatchNo (None, 17, 17, 128)  384         conv2d_38[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 17, 17, 128)  0           batch_normalization_33[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, 17, 17, 128)  0           batch_normalization_38[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_4 (AveragePoo (None, 17, 17, 768)  0           mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_31 (Conv2D)              (None, 17, 17, 192)  147456      mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_34 (Conv2D)              (None, 17, 17, 192)  172032      activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_39 (Conv2D)              (None, 17, 17, 192)  172032      activation_38[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_40 (Conv2D)              (None, 17, 17, 192)  147456      average_pooling2d_4[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_31 (BatchNo (None, 17, 17, 192)  576         conv2d_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_34 (BatchNo (None, 17, 17, 192)  576         conv2d_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_39 (BatchNo (None, 17, 17, 192)  576         conv2d_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_40 (BatchNo (None, 17, 17, 192)  576         conv2d_40[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 17, 17, 192)  0           batch_normalization_31[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 17, 17, 192)  0           batch_normalization_34[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, 17, 17, 192)  0           batch_normalization_39[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, 17, 17, 192)  0           batch_normalization_40[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed4 (Concatenate)            (None, 17, 17, 768)  0           activation_31[0][0]              \n",
      "                                                                 activation_34[0][0]              \n",
      "                                                                 activation_39[0][0]              \n",
      "                                                                 activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_45 (Conv2D)              (None, 17, 17, 160)  122880      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_45 (BatchNo (None, 17, 17, 160)  480         conv2d_45[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, 17, 17, 160)  0           batch_normalization_45[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_46 (Conv2D)              (None, 17, 17, 160)  179200      activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_46 (BatchNo (None, 17, 17, 160)  480         conv2d_46[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, 17, 17, 160)  0           batch_normalization_46[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_42 (Conv2D)              (None, 17, 17, 160)  122880      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_47 (Conv2D)              (None, 17, 17, 160)  179200      activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_42 (BatchNo (None, 17, 17, 160)  480         conv2d_42[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_47 (BatchNo (None, 17, 17, 160)  480         conv2d_47[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, 17, 17, 160)  0           batch_normalization_42[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, 17, 17, 160)  0           batch_normalization_47[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_43 (Conv2D)              (None, 17, 17, 160)  179200      activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_48 (Conv2D)              (None, 17, 17, 160)  179200      activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_43 (BatchNo (None, 17, 17, 160)  480         conv2d_43[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_48 (BatchNo (None, 17, 17, 160)  480         conv2d_48[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, 17, 17, 160)  0           batch_normalization_43[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, 17, 17, 160)  0           batch_normalization_48[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_5 (AveragePoo (None, 17, 17, 768)  0           mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_41 (Conv2D)              (None, 17, 17, 192)  147456      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_44 (Conv2D)              (None, 17, 17, 192)  215040      activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_49 (Conv2D)              (None, 17, 17, 192)  215040      activation_48[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_50 (Conv2D)              (None, 17, 17, 192)  147456      average_pooling2d_5[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_41 (BatchNo (None, 17, 17, 192)  576         conv2d_41[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_44 (BatchNo (None, 17, 17, 192)  576         conv2d_44[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_49 (BatchNo (None, 17, 17, 192)  576         conv2d_49[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_50 (BatchNo (None, 17, 17, 192)  576         conv2d_50[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, 17, 17, 192)  0           batch_normalization_41[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, 17, 17, 192)  0           batch_normalization_44[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_49 (Activation)      (None, 17, 17, 192)  0           batch_normalization_49[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_50 (Activation)      (None, 17, 17, 192)  0           batch_normalization_50[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed5 (Concatenate)            (None, 17, 17, 768)  0           activation_41[0][0]              \n",
      "                                                                 activation_44[0][0]              \n",
      "                                                                 activation_49[0][0]              \n",
      "                                                                 activation_50[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_55 (Conv2D)              (None, 17, 17, 160)  122880      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_55 (BatchNo (None, 17, 17, 160)  480         conv2d_55[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_55 (Activation)      (None, 17, 17, 160)  0           batch_normalization_55[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_56 (Conv2D)              (None, 17, 17, 160)  179200      activation_55[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_56 (BatchNo (None, 17, 17, 160)  480         conv2d_56[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_56 (Activation)      (None, 17, 17, 160)  0           batch_normalization_56[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_52 (Conv2D)              (None, 17, 17, 160)  122880      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_57 (Conv2D)              (None, 17, 17, 160)  179200      activation_56[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_52 (BatchNo (None, 17, 17, 160)  480         conv2d_52[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_57 (BatchNo (None, 17, 17, 160)  480         conv2d_57[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_52 (Activation)      (None, 17, 17, 160)  0           batch_normalization_52[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_57 (Activation)      (None, 17, 17, 160)  0           batch_normalization_57[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_53 (Conv2D)              (None, 17, 17, 160)  179200      activation_52[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_58 (Conv2D)              (None, 17, 17, 160)  179200      activation_57[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_53 (BatchNo (None, 17, 17, 160)  480         conv2d_53[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_58 (BatchNo (None, 17, 17, 160)  480         conv2d_58[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_53 (Activation)      (None, 17, 17, 160)  0           batch_normalization_53[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_58 (Activation)      (None, 17, 17, 160)  0           batch_normalization_58[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_6 (AveragePoo (None, 17, 17, 768)  0           mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_51 (Conv2D)              (None, 17, 17, 192)  147456      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_54 (Conv2D)              (None, 17, 17, 192)  215040      activation_53[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_59 (Conv2D)              (None, 17, 17, 192)  215040      activation_58[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_60 (Conv2D)              (None, 17, 17, 192)  147456      average_pooling2d_6[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_51 (BatchNo (None, 17, 17, 192)  576         conv2d_51[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_54 (BatchNo (None, 17, 17, 192)  576         conv2d_54[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_59 (BatchNo (None, 17, 17, 192)  576         conv2d_59[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_60 (BatchNo (None, 17, 17, 192)  576         conv2d_60[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_51 (Activation)      (None, 17, 17, 192)  0           batch_normalization_51[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_54 (Activation)      (None, 17, 17, 192)  0           batch_normalization_54[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_59 (Activation)      (None, 17, 17, 192)  0           batch_normalization_59[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_60 (Activation)      (None, 17, 17, 192)  0           batch_normalization_60[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed6 (Concatenate)            (None, 17, 17, 768)  0           activation_51[0][0]              \n",
      "                                                                 activation_54[0][0]              \n",
      "                                                                 activation_59[0][0]              \n",
      "                                                                 activation_60[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_65 (Conv2D)              (None, 17, 17, 192)  147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_65 (BatchNo (None, 17, 17, 192)  576         conv2d_65[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_65 (Activation)      (None, 17, 17, 192)  0           batch_normalization_65[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_66 (Conv2D)              (None, 17, 17, 192)  258048      activation_65[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_66 (BatchNo (None, 17, 17, 192)  576         conv2d_66[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_66 (Activation)      (None, 17, 17, 192)  0           batch_normalization_66[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_62 (Conv2D)              (None, 17, 17, 192)  147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_67 (Conv2D)              (None, 17, 17, 192)  258048      activation_66[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_62 (BatchNo (None, 17, 17, 192)  576         conv2d_62[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_67 (BatchNo (None, 17, 17, 192)  576         conv2d_67[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_62 (Activation)      (None, 17, 17, 192)  0           batch_normalization_62[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_67 (Activation)      (None, 17, 17, 192)  0           batch_normalization_67[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_63 (Conv2D)              (None, 17, 17, 192)  258048      activation_62[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_68 (Conv2D)              (None, 17, 17, 192)  258048      activation_67[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_63 (BatchNo (None, 17, 17, 192)  576         conv2d_63[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_68 (BatchNo (None, 17, 17, 192)  576         conv2d_68[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_63 (Activation)      (None, 17, 17, 192)  0           batch_normalization_63[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_68 (Activation)      (None, 17, 17, 192)  0           batch_normalization_68[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_7 (AveragePoo (None, 17, 17, 768)  0           mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_61 (Conv2D)              (None, 17, 17, 192)  147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_64 (Conv2D)              (None, 17, 17, 192)  258048      activation_63[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_69 (Conv2D)              (None, 17, 17, 192)  258048      activation_68[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_70 (Conv2D)              (None, 17, 17, 192)  147456      average_pooling2d_7[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_61 (BatchNo (None, 17, 17, 192)  576         conv2d_61[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_64 (BatchNo (None, 17, 17, 192)  576         conv2d_64[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_69 (BatchNo (None, 17, 17, 192)  576         conv2d_69[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_70 (BatchNo (None, 17, 17, 192)  576         conv2d_70[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_61 (Activation)      (None, 17, 17, 192)  0           batch_normalization_61[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_64 (Activation)      (None, 17, 17, 192)  0           batch_normalization_64[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_69 (Activation)      (None, 17, 17, 192)  0           batch_normalization_69[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_70 (Activation)      (None, 17, 17, 192)  0           batch_normalization_70[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed7 (Concatenate)            (None, 17, 17, 768)  0           activation_61[0][0]              \n",
      "                                                                 activation_64[0][0]              \n",
      "                                                                 activation_69[0][0]              \n",
      "                                                                 activation_70[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_73 (Conv2D)              (None, 17, 17, 192)  147456      mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_73 (BatchNo (None, 17, 17, 192)  576         conv2d_73[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_73 (Activation)      (None, 17, 17, 192)  0           batch_normalization_73[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_74 (Conv2D)              (None, 17, 17, 192)  258048      activation_73[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_74 (BatchNo (None, 17, 17, 192)  576         conv2d_74[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_74 (Activation)      (None, 17, 17, 192)  0           batch_normalization_74[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_71 (Conv2D)              (None, 17, 17, 192)  147456      mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_75 (Conv2D)              (None, 17, 17, 192)  258048      activation_74[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_71 (BatchNo (None, 17, 17, 192)  576         conv2d_71[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_75 (BatchNo (None, 17, 17, 192)  576         conv2d_75[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_71 (Activation)      (None, 17, 17, 192)  0           batch_normalization_71[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_75 (Activation)      (None, 17, 17, 192)  0           batch_normalization_75[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_72 (Conv2D)              (None, 8, 8, 320)    552960      activation_71[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_76 (Conv2D)              (None, 8, 8, 192)    331776      activation_75[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_72 (BatchNo (None, 8, 8, 320)    960         conv2d_72[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_76 (BatchNo (None, 8, 8, 192)    576         conv2d_76[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_72 (Activation)      (None, 8, 8, 320)    0           batch_normalization_72[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_76 (Activation)      (None, 8, 8, 192)    0           batch_normalization_76[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)  (None, 8, 8, 768)    0           mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "mixed8 (Concatenate)            (None, 8, 8, 1280)   0           activation_72[0][0]              \n",
      "                                                                 activation_76[0][0]              \n",
      "                                                                 max_pooling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_81 (Conv2D)              (None, 8, 8, 448)    573440      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_81 (BatchNo (None, 8, 8, 448)    1344        conv2d_81[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_81 (Activation)      (None, 8, 8, 448)    0           batch_normalization_81[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_78 (Conv2D)              (None, 8, 8, 384)    491520      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_82 (Conv2D)              (None, 8, 8, 384)    1548288     activation_81[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_78 (BatchNo (None, 8, 8, 384)    1152        conv2d_78[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_82 (BatchNo (None, 8, 8, 384)    1152        conv2d_82[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_78 (Activation)      (None, 8, 8, 384)    0           batch_normalization_78[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_82 (Activation)      (None, 8, 8, 384)    0           batch_normalization_82[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_79 (Conv2D)              (None, 8, 8, 384)    442368      activation_78[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_80 (Conv2D)              (None, 8, 8, 384)    442368      activation_78[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_83 (Conv2D)              (None, 8, 8, 384)    442368      activation_82[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_84 (Conv2D)              (None, 8, 8, 384)    442368      activation_82[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_8 (AveragePoo (None, 8, 8, 1280)   0           mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_77 (Conv2D)              (None, 8, 8, 320)    409600      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_79 (BatchNo (None, 8, 8, 384)    1152        conv2d_79[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_80 (BatchNo (None, 8, 8, 384)    1152        conv2d_80[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_83 (BatchNo (None, 8, 8, 384)    1152        conv2d_83[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_84 (BatchNo (None, 8, 8, 384)    1152        conv2d_84[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_85 (Conv2D)              (None, 8, 8, 192)    245760      average_pooling2d_8[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_77 (BatchNo (None, 8, 8, 320)    960         conv2d_77[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_79 (Activation)      (None, 8, 8, 384)    0           batch_normalization_79[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_80 (Activation)      (None, 8, 8, 384)    0           batch_normalization_80[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_83 (Activation)      (None, 8, 8, 384)    0           batch_normalization_83[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_84 (Activation)      (None, 8, 8, 384)    0           batch_normalization_84[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_85 (BatchNo (None, 8, 8, 192)    576         conv2d_85[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_77 (Activation)      (None, 8, 8, 320)    0           batch_normalization_77[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed9_0 (Concatenate)          (None, 8, 8, 768)    0           activation_79[0][0]              \n",
      "                                                                 activation_80[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 8, 8, 768)    0           activation_83[0][0]              \n",
      "                                                                 activation_84[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_85 (Activation)      (None, 8, 8, 192)    0           batch_normalization_85[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed9 (Concatenate)            (None, 8, 8, 2048)   0           activation_77[0][0]              \n",
      "                                                                 mixed9_0[0][0]                   \n",
      "                                                                 concatenate_1[0][0]              \n",
      "                                                                 activation_85[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_90 (Conv2D)              (None, 8, 8, 448)    917504      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_90 (BatchNo (None, 8, 8, 448)    1344        conv2d_90[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_90 (Activation)      (None, 8, 8, 448)    0           batch_normalization_90[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_87 (Conv2D)              (None, 8, 8, 384)    786432      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_91 (Conv2D)              (None, 8, 8, 384)    1548288     activation_90[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_87 (BatchNo (None, 8, 8, 384)    1152        conv2d_87[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_91 (BatchNo (None, 8, 8, 384)    1152        conv2d_91[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_87 (Activation)      (None, 8, 8, 384)    0           batch_normalization_87[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_91 (Activation)      (None, 8, 8, 384)    0           batch_normalization_91[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_88 (Conv2D)              (None, 8, 8, 384)    442368      activation_87[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_89 (Conv2D)              (None, 8, 8, 384)    442368      activation_87[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_92 (Conv2D)              (None, 8, 8, 384)    442368      activation_91[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_93 (Conv2D)              (None, 8, 8, 384)    442368      activation_91[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_9 (AveragePoo (None, 8, 8, 2048)   0           mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_86 (Conv2D)              (None, 8, 8, 320)    655360      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_88 (BatchNo (None, 8, 8, 384)    1152        conv2d_88[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_89 (BatchNo (None, 8, 8, 384)    1152        conv2d_89[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_92 (BatchNo (None, 8, 8, 384)    1152        conv2d_92[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_93 (BatchNo (None, 8, 8, 384)    1152        conv2d_93[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_94 (Conv2D)              (None, 8, 8, 192)    393216      average_pooling2d_9[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_86 (BatchNo (None, 8, 8, 320)    960         conv2d_86[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_88 (Activation)      (None, 8, 8, 384)    0           batch_normalization_88[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_89 (Activation)      (None, 8, 8, 384)    0           batch_normalization_89[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_92 (Activation)      (None, 8, 8, 384)    0           batch_normalization_92[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_93 (Activation)      (None, 8, 8, 384)    0           batch_normalization_93[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_94 (BatchNo (None, 8, 8, 192)    576         conv2d_94[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_86 (Activation)      (None, 8, 8, 320)    0           batch_normalization_86[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed9_1 (Concatenate)          (None, 8, 8, 768)    0           activation_88[0][0]              \n",
      "                                                                 activation_89[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 8, 8, 768)    0           activation_92[0][0]              \n",
      "                                                                 activation_93[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_94 (Activation)      (None, 8, 8, 192)    0           batch_normalization_94[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed10 (Concatenate)           (None, 8, 8, 2048)   0           activation_86[0][0]              \n",
      "                                                                 mixed9_1[0][0]                   \n",
      "                                                                 concatenate_2[0][0]              \n",
      "                                                                 activation_94[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_1 (Glo (None, 2048)         0           mixed10[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 2048)         4196352     global_average_pooling2d_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 1)            2049        dense_1[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 26,001,185\n",
      "Trainable params: 25,966,753\n",
      "Non-trainable params: 34,432\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#layer_name = 'global_average_pooling2d_1'\n",
    "layer_name = 'dense_1'\n",
    "intermediate_layer_model = keras.Model(inputs=model.input,\n",
    "                                       outputs=model.get_layer(layer_name).output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1368 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "#messidor2_0:\n",
    "batch_size = 32\n",
    "\n",
    "test_datagen = ImageDataGenerator(samplewise_center = True, rescale=1./255)\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "                                                    '/home/stoledoc/work/datanfs/stoledoc/jama16-retina-replication-master/data/messidor/0/',\n",
    "                                                    target_size=(299, 299),  \n",
    "                                                    color_mode='rgb',\n",
    "                                                    batch_size=batch_size,\n",
    "                                                    class_mode='binary')\n",
    "\n",
    "features_messidor2_0 = intermediate_layer_model.predict(test_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 380 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "#messidor2_1:\n",
    "batch_size = 32\n",
    "\n",
    "test_datagen = ImageDataGenerator(samplewise_center = True, rescale=1./255)\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "                                                    '/home/stoledoc/work/datanfs/stoledoc/jama16-retina-replication-master/data/messidor/1/',\n",
    "                                                    target_size=(299, 299),  \n",
    "                                                    color_mode='rgb',\n",
    "                                                    batch_size=batch_size,\n",
    "                                                    class_mode='binary')\n",
    "\n",
    "features_messidor2_1 = intermediate_layer_model.predict(test_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1368, 2048)\n",
      "(380, 2048)\n"
     ]
    }
   ],
   "source": [
    "print(features_messidor2_0.shape)\n",
    "print(features_messidor2_1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0])"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 380 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "data_dir = '/home/stoledoc/work/datanfs/stoledoc/jama16-retina-replication-master/data/messidor/1/' # path to the directory where the images are stored\n",
    "#index =  0 # select a number here\n",
    "names = []\n",
    "features = []\n",
    "\n",
    "ig = ImageDataGenerator(samplewise_center = True, rescale=1./255)\n",
    "gen = ig.flow_from_directory(data_dir,\n",
    "                             target_size=(299, 299),  \n",
    "                             color_mode='rgb',  \n",
    "                             batch_size = 1  # if you want batch_size > 1 you need to\n",
    "                             )                        # add as many indices as your batch_size.\n",
    "\n",
    "for i in range(380):\n",
    "    image, label = gen._get_batches_of_transformed_samples(np.array([i]))\n",
    "    image_name = gen.filenames[i][2:]\n",
    "    names.append(image_name)\n",
    "    # do whatever you want with your image and label\n",
    "    feature = intermediate_layer_model.predict(image)\n",
    "    features.append(feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = np.asarray(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = np.reshape(features, [380,2048])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "messidor_1 = pd.DataFrame(names)\n",
    "messidor_1.to_csv('messidor_1.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>IM0019.000.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>IM0019.001.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>IM0021.000.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>IM0021.001.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>IM0025.000.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>375</th>\n",
       "      <td>IM1494.001.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>376</th>\n",
       "      <td>IM1511.000.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>377</th>\n",
       "      <td>IM1511.001.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>378</th>\n",
       "      <td>IM1529.000.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>379</th>\n",
       "      <td>IM1529.001.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>380 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  0\n",
       "0    IM0019.000.jpg\n",
       "1    IM0019.001.jpg\n",
       "2    IM0021.000.jpg\n",
       "3    IM0021.001.jpg\n",
       "4    IM0025.000.jpg\n",
       "..              ...\n",
       "375  IM1494.001.jpg\n",
       "376  IM1511.000.jpg\n",
       "377  IM1511.001.jpg\n",
       "378  IM1529.000.jpg\n",
       "379  IM1529.001.jpg\n",
       "\n",
       "[380 rows x 1 columns]"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messidor_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.str_"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(names[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File(\"inceptionv3_features_messidor2_1.hdf5\", \"w\") as datafile:\n",
    "\n",
    "    datafile.create_dataset(\"features\",(380,2048),dtype=np.float32)\n",
    "\n",
    "    datafile[\"features\"][:]=features\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1748 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "data_dir = '/home/stoledoc/work/datanfs/stoledoc/jama16-retina-replication-master/data/messidor2/' # path to the directory where the images are stored\n",
    "#index =  0 # select a number here\n",
    "names = []\n",
    "features = []\n",
    "labels = []\n",
    "\n",
    "ig = ImageDataGenerator(samplewise_center = True, rescale=1./255)\n",
    "gen = ig.flow_from_directory(data_dir,\n",
    "                             target_size=(299, 299),  \n",
    "                             color_mode='rgb',\n",
    "                             class_mode='binary',\n",
    "                             batch_size = 32  # if you want batch_size > 1 you need to\n",
    "                             )                        # add as many indices as your batch_size.\n",
    "\n",
    "for i in range(1748):\n",
    "    image, label = gen._get_batches_of_transformed_samples(np.array([i]))\n",
    "    image_name = gen.filenames[i][2:]\n",
    "    names.append(image_name)\n",
    "    # do whatever you want with your image and label\n",
    "    feature = intermediate_layer_model.predict(image)\n",
    "    features.append(feature)\n",
    "    labels.append(label)\n",
    "    \n",
    "labels = np.asarray(labels)\n",
    "labels = np.reshape(labels, (1748,))\n",
    "\n",
    "features = np.asarray(features)\n",
    "features = np.reshape(features, [1748,2048])\n",
    "\n",
    "messidor = pd.DataFrame(names)\n",
    "messidor.to_csv('messidor_2.csv', index=False, header = False)\n",
    "\n",
    "with h5py.File(\"inceptionv3_features_messidor2_2.hdf5\", \"w\") as datafile:\n",
    "\n",
    "    datafile.create_dataset(\"features\",(1748,2048),dtype=np.float32)\n",
    "    datafile.create_dataset(\"Retinopathy\",(1748,),dtype=np.uint8)\n",
    "\n",
    "    datafile[\"features\"][:]=features\n",
    "    datafile[\"Retinopathy\"][:]=labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8790 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "data_dir = '/home/stoledoc/work/datanfs/stoledoc/jama16-retina-replication-master/data/eyepacs/test/' # path to the directory where the images are stored\n",
    "#index =  0 # select a number here\n",
    "names = []\n",
    "features = []\n",
    "labels = []\n",
    "\n",
    "ig = ImageDataGenerator(samplewise_center = True, rescale=1./255)\n",
    "gen = ig.flow_from_directory(data_dir,\n",
    "                             target_size=(299, 299),  \n",
    "                             color_mode='rgb',\n",
    "                             class_mode='binary',\n",
    "                             batch_size = 32  # if you want batch_size > 1 you need to\n",
    "                             )                        # add as many indices as your batch_size.\n",
    "\n",
    "for i in range(8790):\n",
    "    image, label = gen._get_batches_of_transformed_samples(np.array([i]))\n",
    "    image_name = gen.filenames[i][2:]\n",
    "    names.append(image_name)\n",
    "    # do whatever you want with your image and label\n",
    "    feature = intermediate_layer_model.predict(image)\n",
    "    features.append(feature)\n",
    "    labels.append(label)\n",
    "    \n",
    "labels = np.asarray(labels)\n",
    "labels = np.reshape(labels, (8790))\n",
    "\n",
    "features = np.asarray(features)\n",
    "features = np.reshape(features, [8790,2048])\n",
    "\n",
    "names = pd.DataFrame(names)\n",
    "names.to_csv('kaggle_test_2.csv', index=False, header = False)\n",
    "\n",
    "with h5py.File(\"inceptionv3_features_kaggle_test_2.hdf5\", \"w\") as datafile:\n",
    "\n",
    "    datafile.create_dataset(\"features\",(8790,2048),dtype=np.float32)\n",
    "    datafile.create_dataset(\"Retinopathy\",(8790,),dtype=np.uint8)\n",
    "\n",
    "    datafile[\"features\"][:]=features\n",
    "    datafile[\"Retinopathy\"][:]=labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 56827 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "data_dir = '/home/stoledoc/work/datanfs/stoledoc/jama16-retina-replication-master/data/eyepacs/train/' # path to the directory where the images are stored\n",
    "#index =  0 # select a number here\n",
    "names = []\n",
    "features = []\n",
    "labels = []\n",
    "\n",
    "ig = ImageDataGenerator(samplewise_center = True, rescale=1./255)\n",
    "gen = ig.flow_from_directory(data_dir,\n",
    "                             target_size=(299, 299),  \n",
    "                             color_mode='rgb',\n",
    "                             class_mode='binary',\n",
    "                             batch_size = 32  # if you want batch_size > 1 you need to\n",
    "                             )                        # add as many indices as your batch_size.\n",
    "\n",
    "for i in range(56827):\n",
    "    image, label = gen._get_batches_of_transformed_samples(np.array([i]))\n",
    "    image_name = gen.filenames[i][2:]\n",
    "    names.append(image_name)\n",
    "    # do whatever you want with your image and label\n",
    "    feature = intermediate_layer_model.predict(image)\n",
    "    features.append(feature)\n",
    "    labels.append(label)\n",
    "    \n",
    "labels = np.asarray(labels)\n",
    "labels = np.reshape(labels, (56827))\n",
    "\n",
    "features = np.asarray(features)\n",
    "features = np.reshape(features, [56827,2048])\n",
    "\n",
    "names = pd.DataFrame(names)\n",
    "names.to_csv('kaggle_train_2.csv', index=False, header = False)\n",
    "\n",
    "with h5py.File(\"inceptionv3_features_kaggle_train_2.hdf5\", \"w\") as datafile:\n",
    "\n",
    "    datafile.create_dataset(\"features\",(56827,2048),dtype=np.float32)\n",
    "    datafile.create_dataset(\"Retinopathy\",(56827,),dtype=np.uint8)\n",
    "\n",
    "    datafile[\"features\"][:]=features\n",
    "    datafile[\"Retinopathy\"][:]=labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = \"saved-warm_up_model-{epoch:02d}-{val_loss:.2f}.h5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only = False, mode = 'min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1420/1420 [==============================] - 1541s 1s/step - loss: 0.5820 - accuracy: 0.7142 - auc_1: 0.5739 - val_loss: 0.6696 - val_accuracy: 0.7165 - val_auc_1: 0.6151\n",
      "\n",
      "Epoch 00001: saving model to saved-warm_up_model-01-0.67.h5\n",
      "Epoch 2/20\n",
      "1420/1420 [==============================] - 1457s 1s/step - loss: 0.5597 - accuracy: 0.7244 - auc_1: 0.6316 - val_loss: 0.5478 - val_accuracy: 0.7172 - val_auc_1: 0.6434\n",
      "\n",
      "Epoch 00002: saving model to saved-warm_up_model-02-0.55.h5\n",
      "Epoch 3/20\n",
      "1420/1420 [==============================] - 1481s 1s/step - loss: 0.5523 - accuracy: 0.7328 - auc_1: 0.6498 - val_loss: 0.5509 - val_accuracy: 0.7165 - val_auc_1: 0.6541\n",
      "\n",
      "Epoch 00003: saving model to saved-warm_up_model-03-0.55.h5\n",
      "Epoch 4/20\n",
      "1420/1420 [==============================] - 1402s 987ms/step - loss: 0.5467 - accuracy: 0.7356 - auc_1: 0.6576 - val_loss: 0.5152 - val_accuracy: 0.7170 - val_auc_1: 0.6605\n",
      "\n",
      "Epoch 00004: saving model to saved-warm_up_model-04-0.52.h5\n",
      "Epoch 5/20\n",
      "1420/1420 [==============================] - 816s 575ms/step - loss: 0.5452 - accuracy: 0.7393 - auc_1: 0.6620 - val_loss: 0.6122 - val_accuracy: 0.7175 - val_auc_1: 0.6636\n",
      "\n",
      "Epoch 00005: saving model to saved-warm_up_model-05-0.61.h5\n",
      "Epoch 6/20\n",
      "1420/1420 [==============================] - 1337s 941ms/step - loss: 0.5404 - accuracy: 0.7425 - auc_1: 0.6655 - val_loss: 0.6823 - val_accuracy: 0.7170 - val_auc_1: 0.6669\n",
      "\n",
      "Epoch 00006: saving model to saved-warm_up_model-06-0.68.h5\n",
      "Epoch 7/20\n",
      "1420/1420 [==============================] - 1376s 969ms/step - loss: 0.5384 - accuracy: 0.7426 - auc_1: 0.6682 - val_loss: 0.6079 - val_accuracy: 0.7161 - val_auc_1: 0.6695\n",
      "\n",
      "Epoch 00007: saving model to saved-warm_up_model-07-0.61.h5\n",
      "Epoch 8/20\n",
      "1420/1420 [==============================] - 1374s 967ms/step - loss: 0.5369 - accuracy: 0.7465 - auc_1: 0.6704 - val_loss: 0.6401 - val_accuracy: 0.7169 - val_auc_1: 0.6715\n",
      "\n",
      "Epoch 00008: saving model to saved-warm_up_model-08-0.64.h5\n",
      "Epoch 9/20\n",
      "1420/1420 [==============================] - 1361s 958ms/step - loss: 0.5358 - accuracy: 0.7452 - auc_1: 0.6725 - val_loss: 0.5020 - val_accuracy: 0.7188 - val_auc_1: 0.6736\n",
      "\n",
      "Epoch 00009: saving model to saved-warm_up_model-09-0.50.h5\n",
      "Epoch 10/20\n",
      "1420/1420 [==============================] - 1373s 967ms/step - loss: 0.5335 - accuracy: 0.7472 - auc_1: 0.6747 - val_loss: 0.8898 - val_accuracy: 0.7177 - val_auc_1: 0.6751\n",
      "\n",
      "Epoch 00010: saving model to saved-warm_up_model-10-0.89.h5\n",
      "Epoch 11/20\n",
      "1420/1420 [==============================] - 1372s 967ms/step - loss: 0.5331 - accuracy: 0.7480 - auc_1: 0.6754 - val_loss: 0.5468 - val_accuracy: 0.7178 - val_auc_1: 0.6762\n",
      "\n",
      "Epoch 00011: saving model to saved-warm_up_model-11-0.55.h5\n",
      "Epoch 12/20\n",
      "1420/1420 [==============================] - 1360s 958ms/step - loss: 0.5333 - accuracy: 0.7492 - auc_1: 0.6766 - val_loss: 0.5634 - val_accuracy: 0.7194 - val_auc_1: 0.6773\n",
      "\n",
      "Epoch 00012: saving model to saved-warm_up_model-12-0.56.h5\n",
      "Epoch 13/20\n",
      "1420/1420 [==============================] - 1379s 971ms/step - loss: 0.5314 - accuracy: 0.7498 - auc_1: 0.6778 - val_loss: 0.9701 - val_accuracy: 0.7154 - val_auc_1: 0.6782\n",
      "\n",
      "Epoch 00013: saving model to saved-warm_up_model-13-0.97.h5\n",
      "Epoch 14/20\n",
      "1420/1420 [==============================] - 1379s 971ms/step - loss: 0.5309 - accuracy: 0.7500 - auc_1: 0.6783 - val_loss: 0.5728 - val_accuracy: 0.7181 - val_auc_1: 0.6788\n",
      "\n",
      "Epoch 00014: saving model to saved-warm_up_model-14-0.57.h5\n",
      "Epoch 15/20\n",
      "1420/1420 [==============================] - 1374s 968ms/step - loss: 0.5326 - accuracy: 0.7485 - auc_1: 0.6790 - val_loss: 0.7214 - val_accuracy: 0.7189 - val_auc_1: 0.6794\n",
      "\n",
      "Epoch 00015: saving model to saved-warm_up_model-15-0.72.h5\n",
      "Epoch 16/20\n",
      "1420/1420 [==============================] - 1375s 969ms/step - loss: 0.5297 - accuracy: 0.7490 - auc_1: 0.6799 - val_loss: 0.7459 - val_accuracy: 0.7171 - val_auc_1: 0.6803\n",
      "\n",
      "Epoch 00016: saving model to saved-warm_up_model-16-0.75.h5\n",
      "Epoch 17/20\n",
      "1420/1420 [==============================] - 1384s 975ms/step - loss: 0.5305 - accuracy: 0.7491 - auc_1: 0.6806 - val_loss: 0.6043 - val_accuracy: 0.7181 - val_auc_1: 0.6810\n",
      "\n",
      "Epoch 00017: saving model to saved-warm_up_model-17-0.60.h5\n",
      "Epoch 18/20\n",
      "1420/1420 [==============================] - 1367s 963ms/step - loss: 0.5287 - accuracy: 0.7519 - auc_1: 0.6813 - val_loss: 0.6525 - val_accuracy: 0.7181 - val_auc_1: 0.6816\n",
      "\n",
      "Epoch 00018: saving model to saved-warm_up_model-18-0.65.h5\n",
      "Epoch 19/20\n",
      "1420/1420 [==============================] - 1380s 972ms/step - loss: 0.5286 - accuracy: 0.7509 - auc_1: 0.6820 - val_loss: 0.7094 - val_accuracy: 0.7191 - val_auc_1: 0.6822\n",
      "\n",
      "Epoch 00019: saving model to saved-warm_up_model-19-0.71.h5\n",
      "Epoch 20/20\n",
      "1420/1420 [==============================] - 1381s 972ms/step - loss: 0.5286 - accuracy: 0.7501 - auc_1: 0.6825 - val_loss: 0.7172 - val_accuracy: 0.7169 - val_auc_1: 0.6828\n",
      "\n",
      "Epoch 00020: saving model to saved-warm_up_model-20-0.72.h5\n"
     ]
    }
   ],
   "source": [
    "# train the whole model on the new data for more epochs\n",
    "\n",
    "history = model.fit_generator(train_generator,\n",
    "                    steps_per_epoch = 45463 // batch_size,\n",
    "                    epochs = 20,\n",
    "                    validation_data = val_generator,\n",
    "                    validation_steps = 11364 // batch_size,\n",
    "                    callbacks = [checkpoint]\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.RMSprop(learning_rate = learning_rate, decay = decay)\n",
    "\n",
    "#model.compile(optimizer='rmsprop', loss=mean_xentropy, metrics = ['accuracy'])\n",
    "model.compile(optimizer=optimizer, loss=tf.keras.losses.BinaryCrossentropy(), metrics = ['accuracy',tf.keras.metrics.AUC()])\n",
    "\n",
    "model.load_weights('saved-warm_up_model-04-0.52.h5') # estos son los pesos del warming up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = \"saved-model_2-{epoch:02d}-{val_loss:.2f}.h5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only = False, mode = 'min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1420/1420 [==============================] - 2597s 2s/step - loss: 0.5148 - accuracy: 0.7607 - auc_1: 0.7204 - val_loss: 0.3936 - val_accuracy: 0.7681 - val_auc_1: 0.7313\n",
      "\n",
      "Epoch 00001: saving model to saved-model_2-01-0.39.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/keras/engine/saving.py:165: UserWarning: TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file.You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "  'TensorFlow optimizers do not '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/10\n",
      "1420/1420 [==============================] - 2589s 2s/step - loss: 0.4963 - accuracy: 0.7726 - auc_1: 0.7384 - val_loss: 0.3662 - val_accuracy: 0.7760 - val_auc_1: 0.7446\n",
      "\n",
      "Epoch 00002: saving model to saved-model_2-02-0.37.h5\n",
      "Epoch 3/10\n",
      "1420/1420 [==============================] - 2601s 2s/step - loss: 0.4839 - accuracy: 0.7765 - auc_1: 0.7496 - val_loss: 0.4447 - val_accuracy: 0.7806 - val_auc_1: 0.7541\n",
      "\n",
      "Epoch 00003: saving model to saved-model_2-03-0.44.h5\n",
      "Epoch 4/10\n",
      "1420/1420 [==============================] - 2600s 2s/step - loss: 0.4713 - accuracy: 0.7874 - auc_1: 0.7583 - val_loss: 0.5361 - val_accuracy: 0.7858 - val_auc_1: 0.7621\n",
      "\n",
      "Epoch 00004: saving model to saved-model_2-04-0.54.h5\n",
      "Epoch 5/10\n",
      "1420/1420 [==============================] - 2602s 2s/step - loss: 0.4641 - accuracy: 0.7911 - auc_1: 0.7654 - val_loss: 0.2809 - val_accuracy: 0.7886 - val_auc_1: 0.7684\n",
      "\n",
      "Epoch 00005: saving model to saved-model_2-05-0.28.h5\n",
      "Epoch 6/10\n",
      "1420/1420 [==============================] - 2596s 2s/step - loss: 0.4590 - accuracy: 0.7954 - auc_1: 0.7710 - val_loss: 0.6272 - val_accuracy: 0.7894 - val_auc_1: 0.7733\n",
      "\n",
      "Epoch 00006: saving model to saved-model_2-06-0.63.h5\n",
      "Epoch 7/10\n",
      "1420/1420 [==============================] - 2584s 2s/step - loss: 0.4515 - accuracy: 0.7982 - auc_1: 0.7757 - val_loss: 0.1900 - val_accuracy: 0.7932 - val_auc_1: 0.7780\n",
      "\n",
      "Epoch 00007: saving model to saved-model_2-07-0.19.h5\n",
      "Epoch 8/10\n",
      "1420/1420 [==============================] - 2590s 2s/step - loss: 0.4459 - accuracy: 0.8018 - auc_1: 0.7801 - val_loss: 0.4015 - val_accuracy: 0.7984 - val_auc_1: 0.7822\n",
      "\n",
      "Epoch 00008: saving model to saved-model_2-08-0.40.h5\n",
      "Epoch 9/10\n",
      "1420/1420 [==============================] - 2593s 2s/step - loss: 0.4407 - accuracy: 0.8053 - auc_1: 0.7842 - val_loss: 0.5426 - val_accuracy: 0.8023 - val_auc_1: 0.7860\n",
      "\n",
      "Epoch 00009: saving model to saved-model_2-09-0.54.h5\n",
      "Epoch 10/10\n",
      "1420/1420 [==============================] - 2592s 2s/step - loss: 0.4369 - accuracy: 0.8077 - auc_1: 0.7877 - val_loss: 0.3634 - val_accuracy: 0.7993 - val_auc_1: 0.7893\n",
      "\n",
      "Epoch 00010: saving model to saved-model_2-10-0.36.h5\n"
     ]
    }
   ],
   "source": [
    "# train the whole model on the new data for more epochs\n",
    "\n",
    "history = model.fit_generator(train_generator,\n",
    "                    steps_per_epoch = 45463 // batch_size,\n",
    "                    epochs = 10,\n",
    "                    validation_data = val_generator,\n",
    "                    validation_steps = 11364 // batch_size,\n",
    "                    callbacks = [checkpoint]\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
